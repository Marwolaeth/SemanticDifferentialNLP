@Article{kjell-etal-text-package-2023,
  title = {The text-package: An R-package for Analyzing and Visualizing Human Language Using Natural Language Processing and Deep Learning},
  author = {Oscar Kjell and Salvatore Giorgi and H. Andrew Schwartz},
  journal = {Psychological Methods},
  doi = {10.1037/met0000542},
  year = {2023},
  url = {https://osf.io/preprints/psyarxiv/293kt/},
}

@misc{kjell_giorgi_schwartz_2021,
  title={The text-package: An R-package for Analyzing and Visualizing Human Language Using Natural Language Processing and Deep Learning},
  url={osf.io/preprints/psyarxiv/293kt},
  DOI={10.31234/osf.io/293kt},
  publisher={PsyArXiv},
  author={Kjell, Oscar N E and Giorgi, Salvatore and Schwartz, H. A}, year={2021}, month={Apr}}

@Article{tidyverse-package,
    title = {Welcome to the {tidyverse}},
    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and
      Winston Chang and Lucy D'Agostino McGowan and Romain François and
      Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester
      and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan
      Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson
      and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and
      Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},
    year = {2019},
    journal = {Journal of Open Source Software},
    volume = {4},
    number = {43},
    pages = {1686},
    doi = {10.21105/joss.01686},
}
  
@Manual{pheatmap-package,
  title = {pheatmap: Pretty Heatmaps},
  author = {Raivo Kolde},
  year = {2019},
  version = {1.0.12},
  note = {R package},
  url = {https://CRAN.R-project.org/package=pheatmap},
  doi = {10.32614/CRAN.package.pheatmap},
  license = {GPL-2}
}

@article{honnibal2020spacy,
  added-at = {2023-05-22T04:49:27.000+0200},
  author = {Honnibal, Matthew and Montani, Ines and Van Landeghem, Sofie and Boyd, Adriane},
  biburl = {https://www.bibsonomy.org/bibtex/2616669ca18ac051794c0459373696942/rerry},
  doi = {10.5281/zenodo.1212303},
  interhash = {2d1b3a0bb97e51df1b88d8852cd5ac01},
  intrahash = {616669ca18ac051794c0459373696942},
  keywords = {nlp},
  timestamp = {2023-05-22T04:49:27.000+0200},
  title = {{spaCy: Industrial-strength Natural Language Processing in Python}},
  year = 2020
}

@inproceedings{jang-etal-2022-beyond,
    title = "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
    author = "Jang, Myeongjun  and
      Mtumbuka, Frank  and
      Lukasiewicz, Thomas",
    editor = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2022",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-naacl.156",
    doi = "10.18653/v1/2022.findings-naacl.156",
    pages = "2030--2042",
    abstract = "The logical negation property (LNP), which implies generating different predictions for semantically opposite inputs (p is true iff {\neg}p is false), is an important property that a trustworthy language model must satisfy. However, much recent evidence shows that large-size pre-trained language models (PLMs) do not satisfy this property. In this paper, we perform experiments using probing tasks to assess PLMs{'} LNP understanding. Unlike previous studies that only examined negation expressions, we expand the boundary of the investigation to lexical semantics. Through experiments, we observe that PLMs violate the LNP frequently. To alleviate the issue, we propose a novel intermediate training task, named meaning-matching, designed to directly learn a meaning text correspondence, instead of relying on the distributional hypothesis. Through multiple experiments, we find that the task enables PLMs to learn lexical semantic information. Also, through fine-tuning experiments on 7 GLUE tasks, we confirm that it is a safe intermediate task that guarantees a similar or better performance of downstream tasks. Finally, we observe that our proposed approach outperforms our previous counterparts despite its time and resource efficiency.",
}

@misc{reimers2019sentencebertsentenceembeddingsusing,
      title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks}, 
      author={Nils Reimers and Iryna Gurevych},
      year={2019},
      eprint={1908.10084},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1908.10084}, 
}

@article{DBLP:journals/corr/abs-1911-05758,
  author       = {Timothee Mickus and
                  Denis Paperno and
                  Mathieu Constant and
                  Kees van Deemter},
  title        = {What do you mean, BERT? Assessing {BERT} as a Distributional Semantics
                  Model},
  journal      = {CoRR},
  volume       = {abs/1911.05758},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.05758},
  eprinttype    = {arXiv},
  eprint       = {1911.05758},
  timestamp    = {Sat, 30 Sep 2023 10:08:15 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1911-05758.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}