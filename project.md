## 1. Задача проекта

Что это (имидж и семантический дифференциал), для чего и зачем.


## 2. Требования

валидность и надежность, в том числе:
    - конвергентная концептуальная валидность (что это? как должна проявляться?)
    - дивергентная концептуальная валидность (что это? как должна проявляться?)

## 3. Методы

- нулевая классификация (…)
- близость векторных представлений (…)
- оценка инструктированной модели (…)

## 4. Реализация:

Анонимизация объекта: изначально для удобства извлечения векторного представления именно исследуемого объекта, но оказалось, что так лучше работает и нулевая классификация, а также нормально понимают чат-модели

Нулевая классификация: конкурирующие гипотезы:

- положительный признак, отрицательный и нейтральный (иначе сдвиг в сторону положительного)
- производительность: каждая тройка гипотез проверяется отдельно, включая токенизацию

Близость векторных представлений: разные модели для качественных эмбеддингов

- близость текстов к словам, представляющим концепты, уже применяется в психометрии (Kjell)
- разные методы векторизации текста: CLS, среднее, токен объекта
- метрики: косинусная близость, корреляция Спирмена
- производительность: после однократной векторизации концептов оценка происходит почти моментально

Оценка чат-моделями с инструктированием:

- не было возможности протестировать очень большие модели, токены не использовал принципиально
- напоминает работу с кодировщиками в контент-анализе
- все зависит от хорошо сформулированного запроса
- в запросе специально обговариваем требование дивергентной валидности и ограничиваем фантазию
- задание вернуть JSON работает лучше, чем просто оценка
- JSON не всегда валидный, но мы получаем результаты грубым парсингом
- ужасная производительность: без графического ускорителя работает медленнее, чем человек!

Интерфейс: площадка для экспериментов:

- ввод произвольного текста или случайного из специально подобранных примеров
- настройка семантических шкал с возможностью импорта и экспорта
- выбор модели
- настройки гиперпараметров (не в смысле машинного обучения): формулировка гипотезы, обработка текста, инструкции для чат-моделей.
- возможность выгрузить историю оцененных текстов для дальнейшего анализа и/или разметки

## 5. Результаты
Нулевая классификация:

- хорошая конвергентная валидность: большинство моделей неплохо справляются
- так себе дивергентная валидность
- некоторые модели хуже понимают отрицание, многие не могут определить, кому именно атрибутировать признак: исследуемому объекту или, например, конкурентам, которые упоминаются рядом
- высокая надежность (разные модели для одного и того же текста или одна и та же модель для похожих текстов)

Близость векторных представлений:

- слабая конвергентная валидность (как это проявляется?)
- практически нулевая дивергентная валидность (как это проявляется?)

Инструктирование чат-моделей:

- разные модели показывают разное качество
- модели для креатив (Llama) хуже, чем размышляющие (reasoning) модели (DeepSeek)
- чемпион — Phi4! DeepSeek 14b немного уступает, с меньшей надежностью и отдельнымии спорными решениями
- а еще Phi4 быстрее, чем DeepSeek 14b
- высокая конвергентная и дивергентная валидность, особенно у Phi: с остальными часто можно поспорить
- низкая надежность (разные модели имеют разное мнение, Llama3.2 имеет разное мнение всегда, как сумасшедший шляпник)
- высокая надежность для одной и той же модели (только Phi4) для похожих текстов (парафразов)

## Выводы

Если нужно экономно и быстро — использовать модели-кодировщики, предобученные на задачи NLI. Лучше всего — дообучить еще, не просто на выводы, а на интерпретативные выводы.

Если нужно качественно — использовать Phi4 или более продвинутые модели. DeepSeek размышляет и отвечает по-английски — возможно, он лучше справится с англоязычными текстами. 
    